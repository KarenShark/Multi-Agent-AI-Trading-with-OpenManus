#!/usr/bin/env python3
"""
å†å²æ•°æ®æ”¶é›†è„šæœ¬ - FYPæ ¸å¿ƒè¦æ±‚

å¿«é€Ÿæ”¶é›†2020-2024å¹´S&P 500çœŸå®å†å²æ•°æ®ç”¨äºæ¨¡å‹è®­ç»ƒ
"""

import pandas as pd
import numpy as np
import yfinance as yf
import pickle
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def main():
    """ä¸»è¦çš„æ•°æ®æ”¶é›†æµç¨‹"""
    print("ğŸ“ StockSynergy FYP - å†å²æ•°æ®æ”¶é›†")
    print("=" * 50)

    # é…ç½®
    start_date = "2020-01-01"
    end_date = "2024-01-01"
    prediction_days = 5

    # S&P 500ä¸»è¦è‚¡ç¥¨ï¼ˆç²¾é€‰30åªï¼‰
    stocks = [
        "AAPL", "MSFT", "GOOGL", "AMZN", "TSLA", "META", "NVDA", "JPM", "JNJ", "V",
        "PG", "HD", "UNH", "DIS", "MA", "BAC", "WMT", "PFE", "XOM", "KO",
        "MRK", "CVX", "PEP", "ABBV", "TMO", "COST", "NKE", "MCD", "DHR", "VZ"
    ]

    print(f"ğŸ“… æ”¶é›†æ—¶é—´: {start_date} åˆ° {end_date}")
    print(f"ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {len(stocks)}")

    # 1. æ”¶é›†è‚¡ç¥¨æ•°æ®
    print(f"\nğŸ“¥ ä¸‹è½½è‚¡ç¥¨æ•°æ®...")
    all_data = []
    success_count = 0

    for i, symbol in enumerate(stocks, 1):
        print(f"  {i}/{len(stocks)} {symbol}...", end="")
        try:
            # ä¸‹è½½æ•°æ®
            ticker = yf.Ticker(symbol)
            data = ticker.history(start=start_date, end=end_date)

            if len(data) < 100:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
                print(" âŒ æ•°æ®ä¸è¶³")
                continue

            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            data['Returns'] = data['Close'].pct_change()
            data['SMA_5'] = data['Close'].rolling(5).mean()
            data['SMA_20'] = data['Close'].rolling(20).mean()
            data['RSI'] = calculate_rsi(data['Close'])
            data['Volume_MA'] = data['Volume'].rolling(20).mean()

            # ç”Ÿæˆæ ‡ç­¾ï¼ˆæœªæ¥5å¤©æ”¶ç›Šç‡åˆ†ç±»ï¼‰
            data['Future_Return'] = data['Close'].shift(-prediction_days) / data['Close'] - 1
            data['Label'] = pd.cut(data['Future_Return'],
                                 bins=[-np.inf, -0.02, 0.02, np.inf],
                                 labels=[0, 1, 2])  # 0=ä¸‹è·Œ, 1=æŒå¹³, 2=ä¸Šæ¶¨

            # æ·»åŠ è‚¡ç¥¨æ ‡è¯†
            data['Symbol'] = symbol
            data = data.dropna()

            all_data.append(data)
            success_count += 1
            print(f" âœ… {len(data)}è¡Œ")

        except Exception as e:
            print(f" âŒ {str(e)[:30]}...")

    if not all_data:
        print("âŒ æ²¡æœ‰æˆåŠŸæ”¶é›†åˆ°æ•°æ®")
        return False

    # 2. åˆå¹¶æ•°æ®
    print(f"\nâš™ï¸ åˆå¹¶æ•°æ®...")
    combined_data = pd.concat(all_data, ignore_index=True)
    print(f"  ğŸ“Š æ€»æ ·æœ¬: {len(combined_data):,}")
    print(f"  ğŸ“ˆ æˆåŠŸè‚¡ç¥¨: {success_count}/{len(stocks)}")

    # 3. ä¸‹è½½S&P 500åŸºå‡†
    print(f"\nğŸ“ˆ ä¸‹è½½S&P 500åŸºå‡†...")
    try:
        sp500 = yf.Ticker("^GSPC")
        sp500_data = sp500.history(start=start_date, end=end_date)
        sp500_data['Daily_Return'] = sp500_data['Close'].pct_change()
        sp500_data['Cumulative_Return'] = (1 + sp500_data['Daily_Return']).cumprod() - 1

        total_return = sp500_data['Cumulative_Return'].iloc[-1]
        print(f"  âœ… S&P 500æœŸé—´æ”¶ç›Š: {total_return:.2%}")

    except Exception as e:
        print(f"  âŒ S&P 500æ•°æ®å¤±è´¥: {str(e)}")
        sp500_data = None

    # 4. å‡†å¤‡è®­ç»ƒæ•°æ®
    print(f"\nğŸ”§ å‡†å¤‡è®­ç»ƒæ•°æ®...")

    # é€‰æ‹©ç‰¹å¾åˆ—
    feature_cols = ['Returns', 'SMA_5', 'SMA_20', 'RSI', 'Volume_MA']
    available_features = [col for col in feature_cols if col in combined_data.columns]

    features = combined_data[available_features].fillna(0)
    labels = combined_data['Label'].dropna()

    # ç¡®ä¿ç‰¹å¾å’Œæ ‡ç­¾é•¿åº¦ä¸€è‡´
    min_length = min(len(features), len(labels))
    features = features.iloc[:min_length]
    labels = labels.iloc[:min_length]

    # å‡†å¤‡å…ƒæ•°æ®ï¼ˆåŒ…å«æ—¥æœŸï¼‰
    metadata = combined_data[['Symbol']].iloc[:min_length].copy()
    metadata['date'] = combined_data.index[:min_length]  # æ·»åŠ æ—¥æœŸåˆ—

    print(f"  ğŸ“Š ç‰¹å¾ç»´åº¦: {features.shape}")
    print(f"  ğŸ¯ æ ‡ç­¾åˆ†å¸ƒ: {labels.value_counts().to_dict()}")

    # 5. ä¿å­˜æ•°æ®é›†
    print(f"\nğŸ’¾ ä¿å­˜æ•°æ®é›†...")

    dataset = {
        'features': features,
        'labels': labels,
        'metadata': metadata,  # ç°åœ¨åŒ…å«Symbolå’Œdate
        'sp500_benchmark': sp500_data,
        'dataset_stats': {
            'total_samples': len(features),
            'total_symbols': success_count,
            'feature_count': len(available_features),
            'label_distribution': labels.value_counts().to_dict()
        }
    }

    # åˆ›å»ºç›®å½•å¹¶ä¿å­˜
    os.makedirs("data/historical", exist_ok=True)
    filepath = f"data/historical/complete_dataset_{start_date}_{end_date}.pkl"

    with open(filepath, 'wb') as f:
        pickle.dump(dataset, f)

    file_size = os.path.getsize(filepath) / (1024 * 1024)
    print(f"  âœ… ä¿å­˜æˆåŠŸ: {filepath}")
    print(f"  ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.1f} MB")

    # 6. æ€»ç»“
    print(f"\nğŸ‰ å†å²æ•°æ®æ”¶é›†å®Œæˆï¼")
    print(f"ğŸ“Š æ ·æœ¬æ€»æ•°: {len(features):,}")
    print(f"ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {success_count}")
    print(f"ğŸ”§ ç‰¹å¾æ•°é‡: {len(available_features)}")
    print(f"ğŸš€ å¯è¿è¡Œè®­ç»ƒ: python simple_historical_training.py")

    return True

def calculate_rsi(prices, window=14):
    """è®¡ç®—RSIæŒ‡æ ‡"""
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)